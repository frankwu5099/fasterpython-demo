{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0d71f4",
   "metadata": {},
   "source": [
    "# Efficient Python for Numerical and Scientific Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4cc67d",
   "metadata": {},
   "source": [
    "## Outline\n",
    " - Numpy\n",
    " - Numba\n",
    " - Multiprocessing\n",
    " - torch as numpy with gpu\n",
    " - lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab10f22-01a0-4d30-a5a8-73a0ce726983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numerical python\n",
    "import numba # JIT complier for python\n",
    "from multiprocessing import Pool # multiprocessing\n",
    "import torch # ML library(it can be used for gpu calculation)\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e707df8b",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3a1d3",
   "metadata": {},
   "source": [
    "### Demo 1: numpy is faster than for-loop in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae449786-9e8c-4a0a-8b48-fa1d44c7bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10000)\n",
    "b = np.random.rand(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e2a1e2-4df4-4584-bf73-3fe58cdbf5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 µs, sys: 5 µs, total: 34 µs\n",
      "Wall time: 38.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7720ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10000)\n",
    "b = np.random.rand(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71a2e03-41ac-42f4-bb4d-ee87422b53ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 ms, sys: 0 ns, total: 2.71 ms\n",
      "Wall time: 2.72 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(a)):\n",
    "    a[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f563bc2",
   "metadata": {},
   "source": [
    "### Why is python slow?\n",
    "\n",
    "- **interprete instead of compile**: how the code is executed is not optimized\n",
    "- **dynamic** language: the type of variables are not fixed (cost for analyzing type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49d804",
   "metadata": {},
   "source": [
    "## Quote From [Numpy User Guide](https://numpy.org/doc/stable/user/whatisnumpy.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c61d37",
   "metadata": {},
   "source": [
    "### What is NumPy?\n",
    "NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "\n",
    "At the core of the NumPy package, is the ndarray object. This encapsulates n-dimensional arrays of homogeneous data types, with many operations being performed in compiled code for performance. There are several important differences between NumPy arrays and the standard Python sequences:\n",
    "\n",
    "- NumPy arrays have a fixed size at creation, unlike Python lists (which can grow dynamically). Changing the size of an ndarray will create a new array and delete the original.\n",
    "\n",
    "- The elements in a NumPy array are all required to be of the same data type, and thus will be the same size in memory. The exception: one can have arrays of (Python, including NumPy) objects, thereby allowing for arrays of different sized elements.\n",
    "\n",
    "- NumPy arrays facilitate advanced mathematical and other types of operations on large numbers of data. Typically, such operations are executed more efficiently and with less code than is possible using Python’s built-in sequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a309aa",
   "metadata": {},
   "source": [
    "Vectorization describes the absence of any explicit looping, indexing, etc., in the code - these things are taking place, of course, just “behind the scenes” in **optimized, pre-compiled** **C code**. Vectorized code has many advantages, among which are:\n",
    "\n",
    "- vectorized code is more concise and easier to read\n",
    "\n",
    "- fewer lines of code generally means fewer bugs\n",
    "\n",
    "- the code more closely resembles standard mathematical notation (making it easier, typically, to correctly code mathematical constructs)\n",
    "\n",
    "vectorization results in more “Pythonic” code. Without vectorization, our code would be littered with inefficient and difficult to read for loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdd469",
   "metadata": {},
   "source": [
    "## More on numpy - broadcasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3a95cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "A shape: (2, 3)\n",
      "B:\n",
      " [[1]\n",
      " [2]]\n",
      "B shape: (2, 1)\n",
      "C:\n",
      " [[1 2 3]]\n",
      "C shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "B = np.array([[1],[2]])\n",
    "C = np.array([[1,2,3]])\n",
    "print(\"A:\\n\", A)\n",
    "print(\"A shape:\", A.shape)\n",
    "print(\"B:\\n\", B)\n",
    "print(\"B shape:\", B.shape)\n",
    "print(\"C:\\n\", C)\n",
    "print(\"C shape:\", C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88852624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2fdf4c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 6],\n",
       "       [5, 7, 9]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A+C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a59e5652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 4],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B+C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a2342",
   "metadata": {},
   "source": [
    "### The idea of broadcasting:\n",
    "A (2,3) + B(2,1)<br>\n",
    "It would automately repeat B 3 times along axis 1, so<br>\n",
    "A (2,3) + B_repeat (2,3)<br>\n",
    "\n",
    "B (2,1) + C(1,3)<br>\n",
    "=><br>\n",
    "B_repeat (2,3) + C_repeat (2,3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4598244",
   "metadata": {},
   "source": [
    "![broadcasting.png](broadcasting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91855f07",
   "metadata": {},
   "source": [
    "### Be careful about the dimension of array, especially 1D array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f41945da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G shape: (1, 3)\n",
      "transpose G shape: (3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 4, 6],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = np.array([[1,2,3]])\n",
    "print(\"G shape:\", G.shape)\n",
    "print(\"transpose G shape:\", G.T.shape)\n",
    "G*G.T # T for transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "645de5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G shape: (3,)\n",
      "transpose G shape: (3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = np.array([1,2,3])\n",
    "print(\"G shape:\", G.shape)\n",
    "print(\"transpose G shape:\", G.T.shape)\n",
    "G*G.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10c7c3",
   "metadata": {},
   "source": [
    "### Note for broadcasting: The shapes need to be aligned by the \"last\" dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c8f28b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.array([1,2,3]) #shape:3\n",
    "A.T+D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "183da44f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1374862/3986686288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#shape:2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (2,) "
     ]
    }
   ],
   "source": [
    "D = np.array([1,2]) #shape:2\n",
    "A.T+D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "da17810e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 6]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.array([[1,2,3]]) #shape:1x3\n",
    "A.T+D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0792c",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9548601",
   "metadata": {},
   "source": [
    "### What is Numba?\n",
    "**Quote:** Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code.\n",
    "### What is JIT?\n",
    "**From wiki:** In computing, just-in-time (JIT) compilation (also dynamic translation or run-time compilations) is a way of executing computer code that involves compilation during execution of a program (at run time) rather than before execution. This may consist of source code translation but is more commonly bytecode translation to machine code, which is then executed directly. A system implementing a JIT compiler typically continuously analyses the code being executed and identifies parts of the code where the speedup gained from compilation or recompilation would outweigh the overhead of compiling that code.\n",
    "\n",
    "- Time for compilation while executing\n",
    "- Optimize compilation during running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf3682",
   "metadata": {},
   "source": [
    "### Comparation between numpy, numba.jit, loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b8d474db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(10000)\n",
    "b = np.random.randn(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fa680d",
   "metadata": {},
   "source": [
    "#### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0e24c248-41ea-4086-ac26-9bbe15709d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_sum_loop(a,b):\n",
    "    out = 0\n",
    "    for i in range(len(a)):\n",
    "        out += a[i]*b[i]\n",
    "    return out\n",
    "def f_loop(x):\n",
    "    return product_sum_loop(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1caf7c95-cfbc-486d-8a23-c9c8855ea5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 0 ns, total: 1.69 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [f_loop(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104da2b4",
   "metadata": {},
   "source": [
    "#### Numba.jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "11dff761-2ac7-4efc-8c06-86612b1b3e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def product_sum(a,b):\n",
    "    out = 0\n",
    "    for i in range(len(a)):\n",
    "        out += a[i]*b[i]\n",
    "    return out\n",
    "def f_jit(x):\n",
    "    return product_sum(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7d10d7a0-031e-4f0e-aad9-22f533ba02de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 34.9 ms, total: 138 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [f_jit(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "16f1ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.76 ms, sys: 0 ns, total: 9.76 ms\n",
      "Wall time: 9.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [f_jit(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc88bc",
   "metadata": {},
   "source": [
    "**One can see the time difference between the first time and the second time due to compiling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537ad99",
   "metadata": {},
   "source": [
    "#### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3ff961d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_numpy(x):\n",
    "    return (a*b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c310f418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 0 ns, total: 11.2 ms\n",
      "Wall time: 9.68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [f_numpy(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39f3f0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANtUlEQVR4nO3df6zd9V3H8eeLNugytDraTPm1y4Bg8Acsu9RlmctimGFCh2HID00QIVRmMNHplhqdMRoDyZZoluHYnUMyt5QxwrY2K8M/XGl0KJTJXBniaunClTnKdFfYkhHK2z/u6bi79H7u6eV7ek6/9/n4h3u+55zveYeT3me/5/P9nqaqkCRpKceNewBJ0mQzFJKkJkMhSWoyFJKkJkMhSWpaO+4BRmH9+vU1NTU17jEk6Zjx0EMPPV1VGw53Xy9DMTU1xe7du8c9hiQdM5J8fan7/OhJktRkKCRJTb0KRZJNSWbm5ubGPYok9UavQlFV26tq87p168Y9iiT1Rq9CIUnqnqGQJDUZCklSk6GQJDX18oK7l2Nqy+fGPUJv7b/5onGPIGkFPKKQJDUZCklSk6GQJDUZCklSk6GQJDUZCklSk6GQJDUZCklSk6GQJDUZCklSk6GQJDUZCklSk6GQJDUZCklS08R/zXiSVwJ/DTwH7KyqT4x5JElaVcZyRJHktiRPJdmzaPuFSR5LsjfJlsHmS4G7qup64O1HfVhJWuXG9dHT7cCFCzckWQPcArwNOAe4Ksk5wCnAE4OHHTyKM0qSGFMoqmoX8D+LNm8E9lbVvqp6DrgDuASYZT4W4JqKJB11k/SL92RePHKA+UCcDNwNvCPJh4DtSz05yeYku5PsPnDgwGgnlaRVZJIWs3OYbVVV3wF+c7knV9UMMAMwPT1dHc8mSavWJB1RzAKnLrh9CvDkmGaRJA1MUigeBM5KcnqS44ErgW1HsoMkm5LMzM3NjWRASVqNxnV67FbgfuDsJLNJrquq54EbgXuBR4E7q+qRI9lvVW2vqs3r1q3rfmhJWqXGskZRVVctsX0HsOMojyNJapikj54kSRPIUEiSmnoVChezJal7vQqFi9mS1L1ehUKS1D1DIUlq6lUoXKOQpO71KhSuUUhS93oVCklS9wyFJKnJUEiSmgyFJKmpV6HwrCdJ6l6vQuFZT5LUvV6FQpLUPUMhSWoyFJKkJkMhSWoyFJKkpl6FwtNjJal7vQqFp8dKUvd6FQpJUvcMhSSpyVBIkpoMhSSpyVBIkpoMhSSpqVeh8DoKSeper0LhdRSS1L1ehUKS1D1DIUlqMhSSpCZDIUlqMhSSpCZDIUlqMhSSpCZDIUlq6lUovDJbkrrXq1B4ZbYkda9XoZAkdc9QSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaehUKvz1WkrrXq1D47bGS1L1ehUKS1D1DIUlqMhSSpCZDIUlqMhSSpCZDIUlqMhSSpKa1rTuTbAdqqfur6u2dTyRJmijNUADvH/z3UuAngI8Pbl8F7B/RTJKkCdIMRVXdB5Dkz6vqzQvu2p5k10gnkyRNhGHXKDYkee2hG0lOBzaMZiRJ0iRZ7qOnQ34P2Jlk3+D2FPBbI5lIkjRRhgpFVX0+yVnATw02/XtVfW90Y0mSJsWwRxQAr2f+SGItcG4SqupjI5lKkjQxhgpFkr8DzgAeBg4ONhdgKCSp54Y9opgGzqmqJa+pkCT107BnPe1h/joKSdIqM+wRxXrgq0keAL6/iO2V2ZLUf8OG4k9HOYQkaXINe3rsfUleDZw/2PRAVT01urEkSZNiqDWKJJcDDwC/ClwO/EuSy0Y52ILXfm2Sjya562i8niTpBw27mP1HwPlV9RtVdTWwEXjvck9KcluSp5LsWbT9wiSPJdmbZEtrH1W1r6quG3JOSVLHhl2jOG7RR03fYrjI3A58kAXXWyRZA9wCvBWYBR5Msg1YA9y06PnX+hGXJI3XsKH4fJJ7ga2D21cA9yz3pKralWRq0eaNwN6q2geQ5A7gkqq6Cbh4yHleIslmYDPAaaedttLdSJIWGeqjp6p6N/Bh4OeAc4GZqnrPCl/zZOCJBbdnB9sOK8mJSW4FXpfkDxszzlTVdFVNb9jgF9tKUleG/QqP04EdVXX34PYrkkxV1f4VvGYOs631r+h9C7hhBa8jSerAsIvZnwJeWHD74GDbSswCpy64fQrw5Ar3JUkasWFDsbaqnjt0Y/Dz8St8zQeBs5KcnuR44Epg2wr39QOSbEoyMzc318XuJEkMH4oDSb7/dR1JLgGeXu5JSbYC9wNnJ5lNcl1VPQ/cCNwLPArcWVWPHPnoL1VV26tq87p167rYnSSJ4c96ugH4RJJbmF9PmAWuXu5JVXXVEtt3ADuGHVKSND7DfoXHfwJvSHICkKp6ZrRjSZImxbBf4fHqJB8FPlVVzyQ5J8nEXS3tGoUkdW/YNYrbmV9TOGlw+z+A3x3BPC+LaxSS1L1hQ7G+qu5kcIrsYEH6YPspkqQ+GDYU30lyIoML45K8AfDzHUlaBYY96+ldzF/rcEaSfwI2AEfla8YlSeM17BHFGcDbgDcyv1bxNYaPzFHjYrYkdW/YULy3qv4P+HHgAmAG+NDIplohF7MlqXvDhuLQwvVFwK1V9VlW/hUekqRjyLCh+K8kH2b+n0HdkeSHjuC5kqRj2LC/7C9nfm3iwqr6NvAq4N2jGkqSNDmG/QqP7wJ3L7j9DeAboxpqpZJsAjadeeaZ4x5FknqjVx8fuZgtSd3rVSgkSd0zFJKkJkMhSWoyFJKkJkMhSWrqVSj8ridJ6l6vQuHpsZLUvV6FQpLUPUMhSWoyFJKkJkMhSWoyFJKkJkMhSWrqVSi8jkKSuterUHgdhSR1r1ehkCR1z1BIkpoMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpp6FQqvzJak7vUqFF6ZLUnd61UoJEndMxSSpCZDIUlqMhSSpCZDIUlqMhSSpCZDIUlqMhSSpCZDIUlqMhSSpCZDIUlqMhSSpCZDIUlq6lUo/JpxSeper0Lh14xLUvd6FQpJUvcMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpoMhSSpyVBIkpomPhRJfiXJR5J8NskvjXseSVptRhqKJLcleSrJnkXbL0zyWJK9Sba09lFVn6mq64FrgCtGOK4k6TDWjnj/twMfBD52aEOSNcAtwFuBWeDBJNuANcBNi55/bVU9Nfj5jwfPkyQdRSMNRVXtSjK1aPNGYG9V7QNIcgdwSVXdBFy8eB9JAtwM3FNVXxrlvJKklxrHGsXJwBMLbs8Oti3ld4ALgMuS3LDUg5JsTrI7ye4DBw50M6kkaeQfPR1ODrOtlnpwVX0A+MByO62qGWAGYHp6esn9SZKOzDiOKGaBUxfcPgV4cgxzSJKGMI5QPAicleT0JMcDVwLbuthxkk1JZubm5rrYnSSJ0Z8euxW4Hzg7yWyS66rqeeBG4F7gUeDOqnqki9erqu1VtXndunVd7E6SxOjPerpqie07gB2jfG1JUjcm/spsSdJ4GQpJUlOvQuFitiR1bxzXUYxMVW0Htk9PT18/7ll09Ext+dy4R+it/TdfNO4RNAF6dUQhSeqeoZAkNfUqFK5RSFL3ehUKL7iTpO71ajFb0uTz5IPRGdXJB706opAkdc9QSJKaDIUkqalXofCsJ0nqXq9C4VlPktS9XoVCktQ9QyFJajIUkqQmQyFJakpVjXuGziU5AHx93HMcBeuBp8c9hI6I79mxZ7W8Z6+pqg2Hu6OXoVgtkuyuqulxz6Hh+Z4de3zP/OhJkrQMQyFJajIUx7aZcQ+gI+Z7duxZ9e+ZaxSSpCaPKCRJTYZCktRkKCZUkmfHPYO6keSLSU5Kctfg9nlJfnncc0nDco1iQiV5tqpOGPcc6l6Sa4Dpqrpx3LNIw/CIYsJl3vuS7EnylSRXLLP9LUl2Jfl0kq8muTWJ7/MYJXk2ydTgvToe+DPgiiQPH3rfNBqD/++PJvlIkkeS/H2SVyTZmWR68Jj1SfYPfr4myWeSbE/yeJIbk7wryb8m+eckrxo8bmeSvxocLe5JsjHJcUm+lmTD4DHHJdmbZP3Y/gd0xF8gk+9S4DzgXOAC4H1JfrKxHWAj8PvAzwJnDB6rCVBVzwF/Anyyqs6rqk+Oe6ZV4Czglqr6aeDbwDuWefzPAL/G/J+jvwC+W1WvA+4Hrl7wuFdW1RuB3wZuq6oXgI8Dvz64/wLgy1V1zH/9h6GYfG8CtlbVwar6JnAfcH5jO8ADVbWvqg4CWwePlVarx6vq4cHPDwFTyzz+C1X1TFUdAOaA7YPtX1n03K0AVbUL+NEkPwbcxosxuRb425c5+0QwFJMvR7gdYPHCkwtRWs2+t+Dng8Ba4Hle/P33w43Hv7Dg9guD5x7ykj9nVfUE8M0kvwj8PHDPy5h7YhiKybeL+c+z1ww++3wz8EBjO8DGJKcP1iauAP5xHINrSc8APzLuIVa5/cDrBz9ftsJ9HFoXfBMwV1Vzg+1/w/xHUHcOjuqPeYZi8n0a+Dfgy8A/AO+pqv9ubIf5z1JvBvYAjw8eq/FZ/DfPLwDnuJg9Vu8H3pnki8x/jfhK/O/g+bcC1y3Yvg04gZ587ASeHts7Sd4C/EFVXTzmUQQkORH4UlW9ZtyzqDtJdjL/52z3Ye6bBv6yqn7hqA82ImuXf4iklUhyErCT+b+9ahVIsgV4Jy+e+dQLHlFIkppco5AkNRkKSVKToZAkNRkKSVKToZAkNf0/OzuokbMaJQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "c = [f_loop(i) for i in range(1000)]\n",
    "t1 = time.time()\n",
    "c = [f_jit(i) for i in range(1000)]\n",
    "t2 = time.time()\n",
    "c = [f_numpy(i) for i in range(1000)]\n",
    "t3 = time.time()\n",
    "plt.bar([\"loop\", \"jit\", \"numpy\"], [t1-t0, t2-t1, t3-t2])\n",
    "plt.ylabel(\"second\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf065dd",
   "metadata": {},
   "source": [
    "## More on Numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb9a73",
   "metadata": {},
   "source": [
    "- **vectorize**: you can vectorize a function so that it becomes the element-wise function for numpy array.\n",
    "- **optimization**: jit compilation would optimize your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "951a4c7c-c033-4d7b-ac2c-59e54e5f6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin\n",
    "@numba.vectorize()\n",
    "def nbvc_sin2(x):\n",
    "    return sin(x)*sin(x)\n",
    "@numba.vectorize()\n",
    "def nbvc_sin(x):\n",
    "    return sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6621d12c-23bb-4f7e-aadc-cc1abfafd28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 819 ms, sys: 0 ns, total: 819 ms\n",
      "Wall time: 823 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    nbvc_sin2(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a4940",
   "metadata": {},
   "source": [
    "second time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "80c5c84f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 754 ms, sys: 0 ns, total: 754 ms\n",
      "Wall time: 753 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    nbvc_sin2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6b05baa2-187a-4317-b9c3-f36d5e0798e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 s, sys: 0 ns, total: 1.65 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    np.sin(a)*np.sin(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4ae74",
   "metadata": {},
   "source": [
    "The numpy calculation above is much slower since sin function is excuted twice.<br>\n",
    "**Due to optimization, numba could be much faster than vectorizing operation of numpy(if you are not careful while coding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ff8605ea-638d-4ffb-b0d0-ceb236f644ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 812 ms, sys: 2.06 ms, total: 814 ms\n",
      "Wall time: 811 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    np.sin(a)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126381f",
   "metadata": {},
   "source": [
    "## multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba38970",
   "metadata": {},
   "source": [
    "You can parallelize loop with **multiprocessing.pool** to do calculation with many cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5c2f04d2-e7fa-4fd7-837a-519056274f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.4 s, sys: 3.37 ms, total: 6.4 s\n",
      "Wall time: 6.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = []\n",
    "for i in range(1,20001):\n",
    "    a = np.random.randn(i)\n",
    "    b = np.random.randn(i)\n",
    "    c.append((a*b).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7327c225-c17f-4c36-8de8-21298b07e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 ms, sys: 150 ms, total: 172 ms\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def f(x):\n",
    "    a = np.random.randn(x)\n",
    "    b = np.random.randn(x)\n",
    "    return (a*b).sum()\n",
    "with Pool(5) as p:\n",
    "    c = p.map(f, list(range(20000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa6823",
   "metadata": {},
   "source": [
    "stackoverflow: multiprocessing, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6417b6",
   "metadata": {},
   "source": [
    "### Simple way - use jit with parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "957a2225-4ff0-44cb-a1a3-9ce931c1737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(parallel=True)\n",
    "def nb_pl_product_sum():\n",
    "    c = np.zeros(20001)\n",
    "    for i in numba.prange(1, 20001):\n",
    "        a = np.random.randn(i)\n",
    "        b = np.random.randn(i)\n",
    "        c[i-1] = (a*b).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0756887c-592d-42a5-b455-795bd1124d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.84 s, sys: 10.6 ms, total: 9.86 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = nb_pl_product_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1931a37",
   "metadata": {},
   "source": [
    "second time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b236a178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.46 s, sys: 0 ns, total: 9.46 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = nb_pl_product_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f0df1",
   "metadata": {},
   "source": [
    "## Torch - Using the Power of GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17afd112",
   "metadata": {},
   "source": [
    "![gpuvscpu.png](gpuvscpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dba076",
   "metadata": {},
   "source": [
    "- Nvidia RTX 3080: 8960 cores\n",
    "- Intel Core i9-11900K : 8 cores\n",
    "\n",
    "**If your calculation can be parallelized, GPU might be faster for large-scale arithmetic calculation.**\n",
    " \n",
    "### Pytorch\n",
    "\n",
    "**\"PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\"**\n",
    "- GPU supported\n",
    "- autograd\n",
    "- DL library\n",
    "\n",
    "- other choices: jax, cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d7089",
   "metadata": {},
   "source": [
    "### Comparison between numpy and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c816d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(200000)\n",
    "b = np.random.randn(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3864551f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 ms, sys: 0 ns, total: 146 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [(a*b).sum() for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5cb4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "a = torch.randn(200000,device=\"cuda\")\n",
    "b = torch.randn(200000,device=\"cuda\")\n",
    "def f_torch(x):\n",
    "    return (a*b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e748d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.4 ms, sys: 52.1 ms, total: 104 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [f_torch(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1de020",
   "metadata": {},
   "source": [
    "### Note:\n",
    "In the case above, the speed-up is not significant since `sum` can not be easily parallelized.<br>\n",
    "Consider the case below, which is just the element-wise multiplication. We can find the speed-up is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f5e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = np.random.randn(200000)\n",
    "b = np.random.randn(200000)\n",
    "def f2_numpy(x):\n",
    "    c = (a*b)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf029fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.1 ms, sys: 0 ns, total: 69.1 ms\n",
      "Wall time: 67.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [f2_numpy(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e572139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "a = torch.randn(200000,device=\"cuda\")\n",
    "b = torch.randn(200000,device=\"cuda\")\n",
    "\n",
    "def f2_torch(x):\n",
    "    c = (a*b)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "224547de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.07 ms, sys: 743 µs, total: 7.81 ms\n",
      "Wall time: 6.57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = [f2_torch(i) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ec85e5",
   "metadata": {},
   "source": [
    "## More topic - lru_cache\n",
    "With the decorator `lru_cache`, the return values of certain arguments would be recorded so the calculation won't be executed many times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd25f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "@lru_cache\n",
    "def fibonacci_cache(n):\n",
    "    return fibonacci_cache(n-1) + fibonacci_cache(n-2) if n>=2 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "915000df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 µs, sys: 3 µs, total: 42 µs\n",
      "Wall time: 49.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14930352"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fibonacci_cache(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3ce91afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n):\n",
    "    return fibonacci(n-1) + fibonacci(n-2) if n>=2 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19b6b5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 2.58 ms, total: 1.7 s\n",
      "Wall time: 1.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14930352"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fibonacci(35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
